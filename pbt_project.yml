name: SparkLearningPySpark
description: ''
version: '0.2'
author: sparklearner123@gmail.com
language: python
buildSystem: wheel
pipelines:
  pipelines/BenchmarkInPySpark:
    name: BenchmarkInPySpark
    description: ''
    author: sparklearner123@gmail.com
    mode: batch
    language: python
    createdAt: '2022-10-18 17:42:31'
    datasets:
      inputs:
      - 3736/datasets/TPCH_SF1_LINEITEM
      outputs:
      - 3736/datasets/dataset2
    dependencies: {}
datasets:
  datasets/TPCH_SF1_LINEITEM:
    name: TPCH_SF1_LINEITEM
    description: ''
    author: sparklearner123@gmail.com
    createdAt: '2022-10-18 17:50:07'
    physicalDatasets:
      dev:
        fabricId: 990
        datasetType: Warehouse
        description: ''
        author: sparklearner123@gmail.com
        createdAt: '2022-10-18 17:50:07'
  datasets/lineitem_agg_groupby:
    name: lineitem_agg_groupby
    description: ''
    author: sparklearner123@gmail.com
    createdAt: '2022-10-18 17:56:35'
    physicalDatasets:
      dev:
        fabricId: 990
        datasetType: File
        description: ''
        author: sparklearner123@gmail.com
        createdAt: '2022-10-18 17:56:35'
  datasets/dataset2:
    name: dataset2
    description: ''
    author: sparklearner123@gmail.com
    createdAt: '2022-10-21 17:19:17'
    physicalDatasets:
      dev:
        fabricId: 990
        datasetType: File
        description: ''
        author: sparklearner123@gmail.com
        createdAt: '2022-10-21 17:19:17'
templates: {}
jobs:
  jobs/MyFirstScheduledJob:
    name: MyFirstScheduledJob
    description: ''
    fabricUID: 990
    scheduler:
      Databricks: {}
    jobSize: small
    scheduleCron: 0 0 15/1 * * ? *
    timeout: null
    alerting:
      emails: oncall@acme.com
      onStart: true
      onSuccess: false
      onFailure: true
    pipelines:
    - 3736/pipelines/BenchmarkInPySpark
    jobClusterMode:
      clusterMode:
        Multi: {}
      clusterId: null
    enabled: true
    createdAt: '2022-10-18 18:13:01'
    author: sparklearner123@gmail.com
  jobs/HourlyJob:
    name: HourlyJob
    description: ''
    fabricUID: 990
    scheduler:
      Databricks: {}
    jobSize: small
    scheduleCron: 0 0 15/1 * * ? *
    timeout: null
    alerting:
      emails: oncall@acme.com
      onStart: true
      onSuccess: false
      onFailure: true
    pipelines:
    - 3736/pipelines/BenchmarkInPySpark
    jobClusterMode:
      clusterMode:
        Multi: {}
      clusterId: null
    enabled: true
    createdAt: '2022-10-21 17:38:52'
    author: sparklearner123@gmail.com
libraries: []
subgraphs: {}
dependencies: '[]'
